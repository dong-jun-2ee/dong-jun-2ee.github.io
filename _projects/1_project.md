---
layout: page
title: On Device LLM Serving Engine 
description: Optimizing and supporting language models for execution on NPU backend.
img: assets/img/ondevice.png
importance: 1
category: work
related_publications: false
---


## Summary

We currently working on model acceleration using an NPU backend.

In particular, we are collaborating with machine learning engineers to support language models, optimize model inference, and enhance performance on edge devices. We have achieved very strong performance in this effort.

As this work is confidential, detailed information is closed.